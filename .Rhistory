method = method_meta[1],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[1]])
housePrice_meta
designMat
method_meta[1]
xgbBestTune
train_meta <- house_train[folds_meta[[1]],]
housePrice_meta <- train_meta$housePrice
test_meta <- house_test
meta1[[1]] <- matrix(NA, nrow = dim(test)[1], ncol = length(method_meta) + 2)
meta2[[1]] <- matrix(NA, nrow = dim(train)[1], ncol = length(method_meta))
meta11[[1]] <- matrix(NA, nrow = dim(train)[1], ncol = length(method_meta) + 2)
meta21[[1]] <- matrix(NA, nrow = dim(train)[1], ncol = length(method_meta))
if(method_meta[1] %in% c("xgbTree", "rf")){
designMat <- model.matrix(lm(housePrice_meta~.,data=train_meta))
designMat <- designMat[,-1]
} else if (method_meta[1] %in% c("gbm", "knn")){
designMat <- train_meta[,-1]
}
train(y = housePrice_meta,
x = designMat,
method = method_meta[1],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[1]])
modelfit <- train(y = housePrice_meta,
x = designMat,
method = method_meta[1],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[1]])
modelfit$results
train_meta <- house_train[folds_meta[[1]],]
housePrice_meta <- train_meta$housePrice
test_meta <- house_test
meta1[[1]] <- matrix(NA, nrow = dim(test_meta)[1], ncol = length(method_meta) + 2)
meta2[[1]] <- matrix(NA, nrow = dim(train_meta)[1], ncol = length(method_meta))
meta11[[1]] <- matrix(NA, nrow = dim(train_meta)[1], ncol = length(method_meta) + 2)
meta21[[1]] <- matrix(NA, nrow = dim(train_meta)[1], ncol = length(method_meta))
### I arrange all the best tune and the models for stacking
method_meta <- c("xgbTree", "rf", "gbm", "knn")
parametersTuned_meta <- list(xgbBestTune_meta, forestBestTune_meta, gbmBestTune_meta, knnBestTune_meta)
train_meta<- house_train
test_meta<- house_test
metaPred1<- matrix( NA, nrow = dim(test_meta)[1], ncol = length(method_meta) + 2)
metaPred2<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta))
metaPred11<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta) + 2)
metaPred21<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta))
train_meta<- house_train
housePrice_meta <- train_meta$housePrice
test_meta<- house_test
metaPred1<- matrix( NA, nrow = dim(test_meta)[1], ncol = length(method_meta) + 2)
metaPred2<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta))
metaPred11<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta) + 2)
metaPred21<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta))
train_meta<- house_train
housePrice_meta <- train_meta$housePrice
test_meta<- house_test
metaPred1<- matrix( NA, nrow = dim(test_meta)[1], ncol = length(method_meta) + 2)
metaPred2<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta))
metaPred11<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta) + 2)
metaPred21<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta))
metaPred1
xgbBestTune_meta <- xgbBestTune
forestBestTune_meta <- forestBestTune
gbmBestTune_meta <- gbm_BestTune
knnBestTune_meta <- knnBestTune
### I arrange all the best tune and the models for stacking
method_meta <- c("xgbTree", "rf", "gbm", "knn")
parametersTuned_meta <- list(xgbBestTune_meta, forestBestTune_meta, gbmBestTune_meta, knnBestTune_meta)
train_meta<- house_train
housePrice_meta <- train_meta$housePrice
test_meta<- house_test
metaPred1<- matrix( NA, nrow = dim(test_meta)[1], ncol = length(method_meta) + 2)
metaPred2<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta))
metaPred11<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta) + 2)
metaPred21<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta))
for (j in 1:length(method_meta)){
if(method_meta[j] %in% c("xgbTree", "rf")){
designMat <- model.matrix(lm(housePrice_meta~.,data=train_meta))
designMat <- designMat[,-1]
} else if (method_meta[j] %in% c("gbm", "knn")){
designMat <- train_meta[,-1]
}
modelfit <- train( y = housePrice_meta,
x = designMat,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
metaPred1[,j] <- predict(modelfit, newdata = test_meta)
metaPred2[,j] <- predict(modelfit, newdata = train_meta)
metaPred11[,j] <- predict(modelfit, newdata = train_meta)
metaPred21[,j] <- predict(modelfit, newdata = train_meta)
}
j
designMat
train_meta<- house_train
housePrice_meta <- train_meta$housePrice
test_meta<- house_test
metaPred1<- matrix( NA, nrow = dim(test_meta)[1], ncol = length(method_meta) + 2)
metaPred2<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta))
metaPred11<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta) + 2)
metaPred21<- matrix( NA, nrow = dim(train_meta)[1], ncol = length(method_meta))
for (j in 1:length(method_meta)){
# if(method_meta[j] %in% c("xgbTree", "rf")){
#   designMat <- model.matrix(lm(housePrice_meta~.,data=train_meta))
#   designMat <- designMat[,-1]
# } else if (method_meta[j] %in% c("gbm", "knn")){
#   designMat <- train_meta[,-1]
# }
modelfit <- train( housePrice_meta~.,
data = train_meta,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
metaPred1[,j] <- predict(modelfit, newdata = test_meta)
metaPred2[,j] <- predict(modelfit, newdata = train_meta)
metaPred11[,j] <- predict(modelfit, newdata = train_meta)
metaPred21[,j] <- predict(modelfit, newdata = train_meta)
}
parametersTuned_meta[[j]]
method_meta[j]
train( housePrice_meta~.,
data = train_meta,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
housePrice
housePrice_meta
train_meta
train
train(housePrice~.,
data=train,
method=method[j],
preProc=c("center","scale"),
trControl=trainControl(method="none"),
tuneGrid=parameter[[j]])
train(housePrice_meta~.,
data = train_meta,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
train
train_meta
train(housePrice_meta~.,
data = train,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
housePrice
train_meta$housePrice
housePrice %>% glimpse()
housePrice_meta %>% glimpse()
train(housePrice~.,
data = train,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
colnames(train)
colnames(house_train)
train(housePrice~.,
data = house_train,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
train(house_train$housePrice~.,
data = house_train,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
train_data
train_data$price
train_meta$housePrice
train_data$price == train_meta$housePrice
rm(housePrice)
train_meta<- house_train
housePrice_meta <- train_meta$housePrice
housePrice_meta
train_meta
train(housePrice_meta~.,
data = train_meta,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
train(housePrice~.,
data = house_train,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
housePrice
j
if(method_meta[j] %in% c("xgbTree", "rf")){
designMat <- model.matrix(lm(housePrice_meta~.,data=train_meta))
designMat <- designMat[,-1]
} else if (method_meta[j] %in% c("gbm", "knn")){
designMat <- train_meta[,-1]
}
train(y = house_train$housePrice,
x  = designMat,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
metaPred1<- matrix( NA, nrow = dim(house_test)[1], ncol = length(method_meta) + 2)
metaPred2<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta))
metaPred11<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta) + 2)
metaPred21<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta))
for (j in 1:length(method_meta)){
if(method_meta[j] %in% c("xgbTree", "rf")){
designMat <- model.matrix(lm(housePrice_meta~.,data=train_meta))
designMat <- designMat[,-1]
} else if (method_meta[j] %in% c("gbm", "knn")){
designMat <- train_meta[,-1]
}
modelfit <- train(y = house_train$housePrice,
x  = designMat,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
metaPred1[,j] <- predict(modelfit, newdata = house_test)
metaPred2[,j] <- predict(modelfit, newdata = house_train)
metaPred11[,j] <- predict(modelfit, newdata = house_train)
metaPred21[,j] <- predict(modelfit, newdata = house_train)
}
j
metaPred1<- matrix( NA, nrow = dim(house_test)[1], ncol = length(method_meta) + 2)
metaPred2<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta))
metaPred11<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta) + 2)
metaPred21<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta))
if(method_meta[j] %in% c("xgbTree", "rf")){
designMat <- model.matrix(lm(housePrice_meta~.,data=train_meta))
designMat <- designMat[,-1]
} else if (method_meta[j] %in% c("gbm", "knn")){
designMat <- train_meta[,-1]
}
modelfit <- train(y = house_train$housePrice,
x  = designMat,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
modelfit
xgbBestTune_meta <- xgbBestTune
forestBestTune_meta <- forestBestTune
gbmBestTune_meta <- gbm_BestTune
knnBestTune_meta <- knnBestTune
### I arrange all the best tune and the models for stacking
method_meta <- c("xgbTree", "rf", "gbm", "knn")
parametersTuned_meta <- list(xgbBestTune_meta, forestBestTune_meta, gbmBestTune_meta, knnBestTune_meta)
metaPred1<- matrix( NA, nrow = dim(house_test)[1], ncol = length(method_meta) + 2)
metaPred2<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta))
metaPred11<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta) + 2)
metaPred21<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta))
j <- 1
if(method_meta[j] %in% c("xgbTree", "rf")){
designMat <- model.matrix(lm(house_train$housePrice~.,data=house_train))
designMat <- designMat[,-1]
} else if (method_meta[j] %in% c("gbm", "knn")){
designMat <- house_train[,-1]
}
modelfit <- train(y = house_train$housePrice,
x  = designMat,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
modelfit
metaPred1[,j] <- predict(modelfit, newdata = house_test)
j <- 1
modelfit <- train(house_train$housePrice~.,
data  = house_train,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
housePrice
### Here we perform a simple correlation analysis
housePrice <- train_data$price
housePrice
xgbBestTune_meta <- xgbBestTune
forestBestTune_meta <- forestBestTune
gbmBestTune_meta <- gbm_BestTune
knnBestTune_meta <- knnBestTune
### I arrange all the best tune and the models for stacking
method_meta <- c("xgbTree", "rf", "gbm", "knn")
parametersTuned_meta <- list(xgbBestTune_meta, forestBestTune_meta, gbmBestTune_meta, knnBestTune_meta)
metaPred1<- matrix( NA, nrow = dim(house_test)[1], ncol = length(method_meta) + 2)
metaPred2<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta))
metaPred11<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta) + 2)
metaPred21<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta))
train<- house_train
test<- house_test
j <- 1
modelfit <- train(housePrice~.,
data  = house_train,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
metaPred1[,j] <- predict(modelfit, newdata = house_test)
metaPred2[,j] <- predict(modelfit, newdata = house_train)
metaPred11[,j] <- predict(modelfit, newdata = house_train)
metaPred21[,j] <- predict(modelfit, newdata = house_train)
metaPred1
xgbBestTune_meta <- xgbBestTune
forestBestTune_meta <- forestBestTune
gbmBestTune_meta <- gbm_BestTune
knnBestTune_meta <- knnBestTune
### I arrange all the best tune and the models for stacking
method_meta <- c("xgbTree", "rf", "gbm", "knn")
parametersTuned_meta <- list(xgbBestTune_meta, forestBestTune_meta, gbmBestTune_meta, knnBestTune_meta)
metaPred1<- matrix( NA, nrow = dim(house_test)[1], ncol = length(method_meta) + 2)
metaPred2<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta))
metaPred11<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta) + 2)
metaPred21<- matrix( NA, nrow = dim(house_train)[1], ncol = length(method_meta))
train<- house_train
test<- house_test
for (j in 1:length(method_meta)){
# j <- 1
# if(method_meta[j] %in% c("xgbTree", "rf")){
#
#   designMat <- model.matrix(lm(house_train$housePrice~.,data=house_train))
#   designMat <- designMat[,-1]
#
# } else if (method_meta[j] %in% c("gbm", "knn")){
#
#   designMat <- house_train[,-1]
#
# }
modelfit <- train(housePrice~.,
data  = house_train,
method = method_meta[j],
preProc = c("center","scale"),
trControl = trainControl(method="none"),
tuneGrid = parametersTuned_meta[[j]])
metaPred1[,j] <- predict(modelfit, newdata = house_test)
metaPred2[,j] <- predict(modelfit, newdata = house_train)
metaPred11[,j] <- predict(modelfit, newdata = house_train)
metaPred21[,j] <- predict(modelfit, newdata = house_train)
}
metaPred1
emfit1 <- lm(train$housePrice ~ metaPred2)
emfit1
emfit2 <- train(y = train$housePrice,
x = as.data.frame(metaPred2),
tuneGrid = data.frame(mtry=1:50),
method = "rf", ntree = 150,
trControl = trainControl(method="oob"))
emfit2
plot(emfit2)
emfit11 <- lm(train$housePrice ~ metaPred21)
folds_meta
rm(folds_meta)
folds
rm(folds)
rm(shuffle_meta)
rm(shuffle)
train_meta
rm(train_meta)
View(an)
rm(designMat)
rm(designMatENET)
rm(designMatPCR)
rm(designMatPLS)
rm(designMatRF)
View(ENET_prediction_plot)
View(enetPrediction)
NNET_prediction_plot
View(ENetTune_housePrice)
View(ENET_prediction_plot)
View(LM_prediction_plot)
KNN_prediction_plot
rm(KNN_prediction_plot)
rm(NNET_prediction_plot)
LM_prediction_plot
rm(LM_prediction_plot)
RF_prediction_plot
rm(RF_prediction_plot)
TREE_prediction_plot
rm(TREE_prediction_plot)
GBM_prediction_plot
rm(GBM_prediction_plot)
XGB_prediction_plot
rm(XGB_prediction_plot)
ENET_prediction_plot
rm(ENET_prediction_plot)
PCR_prediction_plot
rm(PCR_prediction_plot)
PLS_prediction_plot
rm(PLS_prediction_plot)
lapply(packagesToLoad, require, character.only = TRUE)
metaStack1
plot(emfit21)
plot(emfit2)
emfit11 <- lm(train$housePrice ~ metaPred21)
emfit21 <- train(y = train$housePrice,
x = as.data.frame(metaPred21),
tuneGrid = data.frame(mtry=1:50),
method = "rf", ntree = 150,
trControl = trainControl(method="oob"))
fittedModelPlot
fit.model
treeBestTune
fit.model <- rpart(house_train[,1]~., data = house_train, cp = treeBestTune)
lapply(packagesToLoad, require, character.only = TRUE)
### Here instead of loading each package seperately, I load all of them at the same time.
packagesToLoad <- c("stringr", "Matrix", "glmnet", "xgboost", "randomForest", "Metrics", "caret", "scales",
"e1071", "corrplot", "psych", "tidyverse", "lubridate", "pls", "gdata", "graphics", "rpart",
"gbm", "earth", "Boruta", "ggcorrplot", "rpart.plot")
lapply(packagesToLoad, require, character.only = TRUE)
fit.model <- rpart(house_train[,1]~., data = house_train, cp = treeBestTune)
fittedModelPlot <- rpart.plot(fit.model, main = "Fitted Model")
plot(xgbTune_housePrice)
xgbTune_housePrice
plot(xgbTune_housePrice)
xgbresults
devtools::install_github("hadley/emo")
require(emo)
designMatENET <- model.matrix(lm(housePrice~.,data=house_train))
designMatENET <- designMat[,-1]
Enet_grid <- expand.grid(alpha = seq(0,.5,length.out=15),
lambda = seq(10,500,length.out=15))
ENetTune_housePrice <- train(y = house_train[,1], x = designMatENET,
method = "glmnet",
preProcess = c("center","scale"),
tuneGrid = Enet_grid,
trControl = trainControl(method="repeatedcv", repeats = 2, number = 10))
ENetTune_housePrice <- train(y = house_train[,1], x = designMatENET,
method = "glmnet",
tuneGrid = Enet_grid,
trControl = trainControl(method="repeatedcv", repeats = 2, number = 10))
pcrBestTune
plot(pcrTune_housePrice)
nnetPrediction
nnetPrediction <- cbind(train_housePrice, NNET_housePrice)%>%as.data.frame()
nnetPrediction <- nnetPrediction/1000000
NNET_prediction_plot <- ggplot(data = nnetPrediction, aes(x = train_housePrice,
y = NNET_housePrice)) + geom_jitter() + geom_smooth(method = loess) +
scale_x_continuous(name = "Train House Price (in Million $)") +
scale_y_continuous(name="NNet Predicted House Price (in Million $)")
NNET_prediction_plot
knnPrediction <- knnPrediction/1000000
KNN_prediction_plot <- ggplot(data = knnPrediction, aes(x = train_housePrice,
y = KNN_housePrice)) + geom_jitter() + geom_smooth(method = loess)+
scale_x_continuous(name = "Train House Price (in Million $)") +
scale_y_continuous(name="kNN Predicted House Price (in Million $)")
KNN_prediction_plot
lmPrediction <- lmPrediction/1000000
LM_prediction_plot <- ggplot(data = lmPrediction, aes(x = train_housePrice,
y = LM_housePrice)) + geom_jitter() + geom_smooth(method = loess)+
scale_x_continuous(name = "Train House Price (in Million $)") +
scale_y_continuous(name="MLR Predicted House Price (in Million $)")
LM_prediction_plot
rfPrediction <- rfPrediction/1000000
RF_prediction_plot <- ggplot(data = rfPrediction, aes(x = train_housePrice,
y = RF_housePrice)) + geom_jitter() + geom_smooth(method = loess)+
scale_x_continuous(name = "Train House Price (in Million $)") +
scale_y_continuous(name="RF Predicted House Price (in Million $)")
RF_prediction_plot
TREE_prediction_plot <- ggplot(data = treePrediction, aes(x = train_housePrice,
y = TREE_housePrice)) + geom_jitter() + geom_smooth(method = loess)+
scale_x_continuous(name = "Train House Price (in Million $)") +
scale_y_continuous(name="Decision Tree Predicted House Price (in Million $)")
treePrediction <- treePrediction/1000000
TREE_prediction_plot <- ggplot(data = treePrediction, aes(x = train_housePrice,
y = TREE_housePrice)) + geom_jitter() + geom_smooth(method = loess)+
scale_x_continuous(name = "Train House Price (in Million $)") +
scale_y_continuous(name="Decision Tree Predicted House Price (in Million $)")
TREE_prediction_plot
gbmPrediction <- gbmPrediction/1000000
GBM_prediction_plot <- ggplot(data = gbmPrediction, aes(x = train_housePrice,
y = GBM_housePrice)) + geom_jitter() + geom_smooth(method = loess)+
scale_x_continuous(name = "Train House Price (in Million $)") +
scale_y_continuous(name="GBM Predicted House Price (in Million $)")
GBM_prediction_plot
xgbPrediction <- xgbPrediction/1000000
XGB_prediction_plot <- ggplot(data = xgbPrediction, aes(x = train_housePrice,
y = XGB_housePrice)) + geom_jitter() + geom_smooth(method = loess)+
scale_x_continuous(name = "Train House Price (in Million $)") +
scale_y_continuous(name="XGB Predicted House Price (in Million $)")
XGB_prediction_plot
enetPrediction <- enetPrediction/1000000
ENET_prediction_plot <- ggplot(data = enetPrediction, aes(x = train_housePrice,
y = ENET_housePrice)) + geom_jitter() + geom_smooth(method = loess)+
scale_x_continuous(name = "Train House Price (in Million $)") +
scale_y_continuous(name="ENET Predicted House Price (in Million $)")
ENET_prediction_plot
pcrPrediction <- pcrPrediction/1000000
PCR_prediction_plot <- ggplot(data = pcrPrediction, aes(x = train_housePrice,
y = PCR_housePrice)) + geom_jitter() + geom_smooth(method = loess)+
scale_x_continuous(name = "Train House Price (in Million $)") +
scale_y_continuous(name="PCR Predicted House Price (in Million $)")
PCR_prediction_plot
plsPrediction <- plsPrediction/1000000
PLS_prediction_plot <- ggplot(data = plsPrediction, aes(x = train_housePrice,
y = PLS_housePrice)) + geom_jitter() + geom_smooth(method = loess)+
scale_x_continuous(name = "Train House Price (in Million $)") +
scale_y_continuous(name="PLS Predicted House Price (in Million $)")
PLS_prediction_plot
