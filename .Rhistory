#loading libraries
library(psych)
library(corrplot)
library(caret)
library(tidyverse)
library(lubridate)
# library(MASS)
require(pls)
library(glmnet)
# library(fields)
library(gdata)
library(Matrix)
# library(cubature)
library(graphics)
library(rpart)
library(randomForest)
library(gbm)
library(earth)
train_data <- read.csv("./Data/train.csv")
test_data <- read.csv("./Data/test.csv")
train_data$date <- ymd(train_data$date)
train_data %>% glimpse()
test_data %>% glimpse()
trainData <- train_data %>%select(-property,-date)
trainData$waterfront <- as.factor(trainData$waterfront)
trainData$condition <- as.factor(trainData$condition)
library(ggcorrplot)
trainData%>%glimpse()
ggcorrplot(cor(trainData), p.mat = cor_pmat(trainData), hc.order=TRUE, type='lower')
cor_pmat(trainData)
trainData
train_data <- read.csv("./Data/train.csv")
test_data <- read.csv("./Data/test.csv")
train_data$date <- ymd(train_data$date)
train_data %>% glimpse()
test_data %>% glimpse()
train_data%>%glimpse()
trainData <- train_data %>%select(-property,-date)
ggcorrplot(cor(trainData), p.mat = cor_pmat(trainData), hc.order=TRUE, type='lower')
trainData$waterfront <- as.factor(trainData$waterfront)
trainData$condition <- as.factor(trainData$condition)
library(ggcorrplot)
trainData%>%glimpse()
ggcorrplot(cor(trainData), p.mat = cor_pmat(trainData), hc.order=TRUE, type='lower')
detach("package:MASS", unload=TRUE)
train_data <- train_data%>%select(property,price,date,bedrooms:sqft_lot15)%>%as.data.frame()
train_data <- train_data %>% select(price:sqft_lot15)
priceplot <- ggplot(data = train_data,aes(x=price))+geom_histogram(fill="Green")+
scale_x_continuous(breaks= seq(min(train_data$price), max(train_data$price), by=1000000))
priceplot
housePrice <- train_data$price
correlationMatrix <- cor(cbind(housePrice,train_in))
correlationMatrix_sorted <- as.matrix(sort(correlationMatrix[,'housePrice'], decreasing = TRUE))
housePrice <- train_data$price
correlationMatrix <- cor(cbind(housePrice,train_data))
#Lets see how the house prices are affected by the year the houses are built
price_YearBuilt <- train_data %>% ggplot(aes(x=yr_built,y=price))+geom_point()+
scale_y_continuous(breaks= seq(min(train_data$price), max(train_data$price), by=1000000))
price_YearBuilt
#Fitting a multiple linear regression to find significant explanatory variables
mreg <- lm(price ~ . , data=train_data)
an <- anova(mreg)
an
impVar_lm <- varImp(mreg)
impVar_lm
?varImp
#Here we are removing date from the data since the houses sold are in the same year.
train_in <- train_data%>%select(bedrooms:sqft_lot15)
train_in%>%glimpse()
house_train <- cbind(housePrice,train_in)%>%as.data.frame()
#changing zipcode to factor variable since it is not an integer/numeric variable
house_train$zipcode <- as.factor(house_train$zipcode)
#Removing latitude and longitude from the data. Since it adds extraneous information to our data.
#Another reson for removing the latitide and longitude is because we are least interested in spatial analysis
#We are also dropping sqft_living, sqft_lot,sqft_above, and sqft_basement since we have sqft_living15 and sqft_lot15
#and those variables adds unnecessary information
house_train <- house_train%>%select(-lat,-long,-sqft_above, -sqft_basement, -sqft_living15, -sqft_lot15)
#changing the waterfront to factor since it is an indicator
house_train$waterfront <- as.factor(house_train$waterfront)
#changing the condition to a factor since it is a rating
house_train$condition <- as.factor(house_train$condition)
house_train%>%glimpse()
house_test <- test_data %>% select(bedrooms:sqft_lot15)
house_test <- house_test %>% select(-lat,-long,-sqft_above, -sqft_basement, -sqft_living15, -sqft_lot15)
house_test$zipcode <- as.factor(house_test$zipcode)
house_test$waterfront <- as.factor(house_test$waterfront)
house_test$condition <- as.factor(house_test$condition)
house_test %>% glimpse()
# tuneGrid=data.frame(cp=seq(.001,.01,length.out = 10)),
TreeTune_housePricing<-train(y=house_train[,1],x=house_train[,2:13],
method="rpart",tuneGrid=data.frame(cp=seq(.0001,.1,length.out = 50)),
trControl=trainControl(method="repeatedcv",repeats=100,number=10))
TreeTune_housePricing
house_train[,1]
house_train
house_train %>% arrange(housePrice)
house_train %>% sort(housePrice)
house_train %>% arrange(housePrice, desc())
house_train %>% arrange(housePrice)%>% tail()
TreeTune_housePricing$bestTune
TreeTune_housePricing$results
housePricePredict_Tree <- predict(TreeTune_housePricing,house_test)
housePricePredict_Tree <- round(as.data.frame(housePricePredict_Tree),3)
names(housePricePredict_Tree) <- "price"
housePricePredict_Tree
nrow(housePricePredict_Tree)
nrow(house_test)
GbmTune_housePricing
TreeTune_housePricing
Tree_housePrice <- predict(TreeTune_housePricing,house_train)
TreePrediction <- cbind(train_housePrice,Tree_housePrice)%>%as.data.frame()
train_housePrice
train_housePrice <- house_train$housePrice
Tree_housePrice <- predict(TreeTune_housePricing,house_train)
TreePrediction <- cbind(train_housePrice,Tree_housePrice)%>%as.data.frame()
Tree_prediction_plot <- ggplot(data=TreePrediction,aes(x=train_housePrice,
y=Tree_housePrice))+geom_jitter()+geom_smooth(method = loess)
Tree_prediction_plot
TreePrediction
house_train
house_test
house_train
Tree_housePrice <- predict(TreeTune_housePricing,house_train %>% select(-housePrice))
TreePrediction
TreePrediction <- cbind(train_housePrice,Tree_housePrice)%>%as.data.frame()
TreePrediction
Tree_prediction_plot <- ggplot(data=TreePrediction,aes(x=train_housePrice,
y=Tree_housePrice))+geom_jitter()+geom_smooth(method = loess)
Tree_prediction_plot
TreePrediction
TreePrediction %>% mutate(absDiff = abs(train_housePrice-Tree_housePrice))
TreePrediction %>% mutate(absDiff = RMSE(train_housePrice-Tree_housePrice))
RMSE(TreePrediction$train_housePrice, TreePrediction$Tree_housePrice)
TreePrediction$train_housePrice - TreePrediction$Tree_housePrice
#loading libraries
library(psych)
library(corrplot)
library(caret)
library(tidyverse)
library(lubridate)
# library(MASS)
require(pls)
library(glmnet)
# library(fields)
library(gdata)
library(Matrix)
# library(cubature)
library(graphics)
library(rpart)
library(randomForest)
library(gbm)
library(earth)
### Here instead of loading each package seperately, I load all of them at the same time.
packagesToLoad <- c("stringr", "Matrix", "glmnet", "xgboost", "randomForest", "Metrics", "caret", "scales",
"e1071", "corrplot", "psych", "tidyverse", "lubridate", "pls", "gdata", "graphics", "rpart",
"gbm", "earth", "Boruta", "ggcorrplot")
lapply(packagesToLoad, require, character.only = TRUE)
# Reading training and testing data
train_data <- read.csv("./Data/train.csv")
test_data <- read.csv("./Data/test.csv")
### Converting date to ymd format
train_data$date <- ymd(train_data$date)
train_data <- train_data %>% select(price:sqft_lot15)
### This plot simply plots the density of house prices as histogram.
priceplot <- ggplot(data = train_data,aes(x=price))+geom_histogram(fill="Grey")+
scale_x_continuous(breaks= seq(min(train_data$price), max(train_data$price), by=1000000))
priceplot
### Here we perform a simple correlation analysis
housePrice <- train_data$price
correlationMatrix <- cor(cbind(housePrice,train_data %>% select(-price)))
correlationMatrix_sorted <- as.matrix(sort(correlationMatrix[,'housePrice'], decreasing = TRUE))
correlationMatrix_sorted
#Lets see how the house prices are affected by the year the houses are built
price_YearBuilt <- train_data %>% ggplot(aes(x=yr_built,y=price))+geom_point()+
scale_y_continuous(breaks= seq(min(train_data$price), max(train_data$price), by=1000000))
## Fitting a multiple linear regression to find significant explanatory variables
mreg <- lm(price ~ . , data=train_data)
an <- anova(mreg)
#The ANOVA table above concludes that almost all the explanatory variables are significant explaining the price of the house
impVar_lm <- varImp(mreg)
impVar_lm
# I am using XG boost to further analyze variable importance
designX <- train_data %>% select(-price)
xgBoost_fit <- xgboost(data.matrix(designX), train_data$price, nrounds=800)
xgBoost_Imp <- xgb.importance(model = xgBoost_fit, feature_names = names(designX))
xgBoost_Imp
xgBoost_Imp
Boruta(price~. , data = train_data)
### Here instead of loading each package seperately, I load all of them at the same time.
packagesToLoad <- c("stringr", "Matrix", "glmnet", "xgboost", "randomForest", "Metrics", "caret", "scales",
"e1071", "corrplot", "psych", "tidyverse", "lubridate", "pls", "gdata", "graphics", "rpart",
"gbm", "earth", "Boruta", "ggcorrplot")
lapply(packagesToLoad, require, character.only = TRUE)
Boruta(price~. , data = train_data)
#### I am also using Boruta feature selection algorithm to determine the variable importance
boruta_fit <- Boruta(price~. , data = train_data , doTrace = 2)
print(boruta_fit)
# Boruta performed 68 iterations in 15.85281 mins.
# 18 attributes confirmed important: bathrooms,
# bedrooms, condition, floors, grade and 13 more;
# No attributes deemed unimportant.
plot(boruta_fit)
boruta_fit
boruta_fit$ImpHistory
boruta_fit$impSource
boruta_fit$pValue
boruta_fit$ImpHistory
nrow(boruta_fit$ImpHistory)
colMeans(boruta_fit$ImpHistory)
colMeans(boruta_fit$ImpHistory)
house_train$zipcode <- as.factor(house_train$zipcode)
#### I change the waterfront and condition variable to factor variable.
## Waterfront is a binary variable and condition is the rating variable. So we change them to factor.
house_train$waterfront <- as.factor(house_train$waterfront)
house_train$condition <- as.factor(house_train$condition)
# I am dropping sqft_living, sqft_lot,sqft_above, and sqft_basement.
# sqft_living15 and sqft_lot15 contain most recent information about the sqft information
house_train <- house_train %>% select(-sqft_above, -sqft_basement, -sqft_living, -sqft_lot)
################# Replicating the same changes in test data set
house_test <- test_data %>% select(bedrooms:sqft_lot15)
house_test$zipcode <- as.factor(house_test$zipcode)
house_test$waterfront <- as.factor(house_test$waterfront)
house_test$condition <- as.factor(house_test$condition)
house_test <- house_test %>% select(-sqft_above, -sqft_basement, -sqft_living, -sqft_lot)
# Here I am  removing date from the data since the houses sold are in the same year.
train_in <- train_data %>% select(bedrooms:sqft_lot15)
house_train <- cbind(housePrice,train_in) %>% as.data.frame()
# Changing zipcode to factor variable since it is not an integer/numeric variable
house_train$zipcode <- as.factor(house_train$zipcode)
#### I change the waterfront and condition variable to factor variable.
## Waterfront is a binary variable and condition is the rating variable. So we change them to factor.
house_train$waterfront <- as.factor(house_train$waterfront)
house_train$condition <- as.factor(house_train$condition)
# I am dropping sqft_living, sqft_lot,sqft_above, and sqft_basement.
# sqft_living15 and sqft_lot15 contain most recent information about the sqft information
house_train <- house_train %>% select(-sqft_above, -sqft_basement, -sqft_living, -sqft_lot)
################# Replicating the same changes in test data set
house_test <- test_data %>% select(bedrooms:sqft_lot15)
house_test$zipcode <- as.factor(house_test$zipcode)
house_test$waterfront <- as.factor(house_test$waterfront)
house_test$condition <- as.factor(house_test$condition)
house_test <- house_test %>% select(-sqft_above, -sqft_basement, -sqft_living, -sqft_lot)
house_train
?trainControl
knnTune_housePrice <- train(y = house_train[,1], x = house_train[,2:13],
method = "knn",
preProcess = c("center","scale"),
tuneGrid = data.frame(.k=1:20),
trControl = trainControl(method = "repeatedcv", repeats = 100, number = 10))
knnTune_housePrice$bestTune
knnTune_housePrice$results
train(y = house_train[,1], x = house_train[,2:13],
method = "knn",
preProcess = c("center","scale"),
tuneGrid = data.frame(.k=1:20),
trControl = trainControl(method = "repeatedcv", repeats = 20, number = 10))
knnTune_housePrice$bestTune
knnTune_housePrice <- train(y = house_train[,1], x = house_train[,2:13],
method = "knn",
preProcess = c("center","scale"),
tuneGrid = data.frame(.k=1:20),
trControl = trainControl(method = "repeatedcv", repeats = 20, number = 10))
knnTune_housePrice
plot(knnTune_housePrice)
knnTune_housePrice$bestTune
knnTune_housePrice$results
cv.control_house
seq(from = 1, to = 5,length.out = 5)
seq(from = .3, to = .8, length.out = 6)
nnet.grid <- expand.grid(size = seq(from = 1, to = 5, length.out = 5),
decay = seq(from = .3, to = .8, length.out = 6))
nnetTune_housePrice <- train(y = house_train[,1], x = house_train[,2:13],
method = "nnet", trace = FALSE,
preProc = c("center","scale"),
linout = TRUE, tuneGrid = nnet.grid,
maxit = 50,
trControl = trainControl(method = "repeatedcv", repeats = 10, number = 10) )
nnetTune_housePrice
nnet.grid <- expand.grid(size = seq(from = 1, to = 5, length.out = 5),
decay = seq(from = .3, to = .8, length.out = 6))
nnetTune_housePrice <- train(y = house_train[,1], x = house_train[,2:13],
method = "nnet", trace = FALSE,
preProc = c("center","scale"),
linout = TRUE, tuneGrid = nnet.grid,
maxit = 50,
trControl = trainControl(method = "repeatedcv", repeats = 2, number = 10) )
nnetTune_housePrice
plot(nnetTune_housePrice)
nnetTune_housePrice$bestTune
nnetTune_housePrice$results
lmTune_housePrice <- train(housePrice~., data = house_train,
method = "lm",
trControl = trainControl(method = "repeatedcv",
repeats = 2, number = 10))
lmTune_housePrice
plot(lmTune_housePrice)
lmTune_housePrice$results
data.frame(mtry=1:100)
forestTune_housePrice <- train(y = house_train[,1], x = house_train[,2:13],
tuneGrid = data.frame(mtry=1:100),
method = "rf", ntree = 500,
trControl = trainControl(method="oob"))
dummyMat <- model.matrix(lm(housePrice~.,data=house_train))
dummyMat <- dummyMat[,-1]
dummyMat
model.matrix(lm(housePrice~.,data=house_train))
########################################################################################################
####################################### USING RANDOM FOREST ############################################
########################################################################################################
designMat <- model.matrix(lm(housePrice~.,data=house_train))
designMat <- designMat[,-1]
forestTune_housePrice <- train(y = house_train[,1], x = designMat,
tuneGrid = data.frame(mtry=1:100),
method = "rf", ntree = 500,
trControl = trainControl(method="oob"))
